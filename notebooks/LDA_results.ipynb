{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tweets = pd.read_csv('../tweets/tweets_clean.csv',\n",
    "                     header=0,\n",
    "                     parse_dates=['date'])\n",
    "tweets.dropna(subset=['lemmas'], inplace=True)\n",
    "tweets.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Load vectorizer\n",
    "with open('../scripts/topic_modeling_objects/sklearn_vect.joblib', 'rb') as f:\n",
    "    cv = joblib.load(f)\n",
    "\n",
    "# Load term frequency matrix\n",
    "with open('../scripts/topic_modeling_objects/sklearn_CV.joblib', 'rb') as f:\n",
    "    tf = joblib.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open('../scripts/topic_modeling_objects/sklearn_feature_names.joblib', 'rb') as f:\n",
    "    tf_names = joblib.load(f)\n",
    "\n",
    "# Load fitted LDA model\n",
    "with open('../scripts/topic_modeling_objects/sklearn_LDA_model.joblib', 'rb') as f:\n",
    "    lda_model = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: trump want news tell politic win break try post way attack pay donald tweet twitter\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 1: vote american trump right campaign people big watch muslim job family happy illegal true pjnet\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 2: realdonaldtrump call give debate trump money make hate become bring question school hope high order\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 3: trump clinton america election great come may voter politic war mean poll russia republican news\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 4: obama hillaryclinton gop bill isis dnc clinton care terrorist neverhillary game check kid music claim\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 5: black president state first trump talk real potus start bad party join turn top ask\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 6: love trump law lead late fire hear russian cruz miss government blacklivesmatter little fall photo\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 7: take time stop live pjnet lose ccot democrat many gun word truth anti wakeupamerica national\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 8: know medium work email even clinton ever fbi fact candidate city send death buy head\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 9: video blicqer thank die play free must nothing stand feel merkelmussbleiben sign wait merkel matter\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 10: new trump show year maga report supporter put wikileak something face speech release news point\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 11: hillary day think see country find run last always happen people guy follow night racist\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 12: make need white midnight support lie world leave still really house help read end child\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 13: woman man never life back police change old fight girl year home shoot power forget\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 14: good tcot look today kill keep liberal friend refugee usa trumpforpresident someone well week god\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tweets_orig = tweets.text.tolist()\n",
    "tweet_docs = tweets.lemmas.tolist()\n",
    "\n",
    "# Topic to document matrix (W) for LDA model\n",
    "lda_W = lda_model.transform(tf)\n",
    "# Word to topics matrix (H) for LDA model\n",
    "lda_H = lda_model.components_\n",
    "\n",
    "\n",
    "def display_topics(H, W, feature_names, orig_docs, n_words=15, n_docs=25):\n",
    "    for i, topic in enumerate(H):\n",
    "        print('Topic {}: '.format(i) + ' '.join([feature_names[word]\n",
    "                                                 for word in topic.argsort()[: (-n_words - 1): -1]]))\n",
    "        print()\n",
    "        top_doc_ids = np.argsort(W[:, i])[:: -1][0: n_docs]\n",
    "        for doc_id in top_doc_ids:\n",
    "            print('Tweet:', repr(orig_docs[doc_id]))\n",
    "        print('-' * 80)\n",
    "\n",
    "\n",
    "display_topics(lda_H, lda_W, tf_names, tweets_orig, n_docs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = ['Topic' + str(i) for i in range(len(lda_model.components_))]\n",
    "doc_names = ['Doc' + str(i) for i in range(len(tweet_docs))]\n",
    "word_names = ['Word ' + str(i) for i in range(len(tf_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  \\\n",
      "Doc0    0.03    0.03    0.03    0.53    0.03    0.03    0.03    0.03    0.03   \n",
      "Doc1    0.07    0.07    0.07    0.07    0.07    0.07    0.07    0.07    0.07   \n",
      "Doc2    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
      "Doc3    0.03    0.03    0.03    0.03    0.03    0.03    0.53    0.03    0.03   \n",
      "Doc4    0.18    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
      "Doc5    0.38    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
      "Doc6    0.01    0.01    0.01    0.72    0.15    0.01    0.01    0.01    0.01   \n",
      "Doc7    0.53    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03   \n",
      "Doc8    0.84    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
      "Doc9    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.53    0.03   \n",
      "\n",
      "      Topic9  Topic10  Topic11  Topic12  Topic13  Topic14  dominant_topic  \n",
      "Doc0    0.03     0.03     0.03     0.03     0.03     0.03               3  \n",
      "Doc1    0.07     0.07     0.07     0.07     0.07     0.07               0  \n",
      "Doc2    0.81     0.01     0.01     0.01     0.01     0.01               9  \n",
      "Doc3    0.03     0.03     0.03     0.03     0.03     0.03               6  \n",
      "Doc4    0.01     0.01     0.68     0.01     0.01     0.01              11  \n",
      "Doc5    0.01     0.01     0.01     0.01     0.51     0.01              13  \n",
      "Doc6    0.01     0.01     0.01     0.01     0.01     0.01               3  \n",
      "Doc7    0.03     0.03     0.03     0.03     0.03     0.03               0  \n",
      "Doc8    0.01     0.01     0.01     0.01     0.01     0.01               0  \n",
      "Doc9    0.03     0.03     0.03     0.03     0.03     0.03               7  \n"
     ]
    }
   ],
   "source": [
    "# Create df with the topic probabilities (cols) for each doc (rows)\n",
    "doc_topic_df = pd.DataFrame(np.round(lda_W, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# Add column with dominant topic for each doc\n",
    "doc_topic_df['dominant_topic'] = np.argmax(doc_topic_df.values, axis=1)\n",
    "print(doc_topic_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Topic_num  Num_docs  Proportion\n",
      "0           0     38583    0.190499\n",
      "1           1     20961    0.103492\n",
      "2           3     17749    0.087633\n",
      "3           2     17081    0.084335\n",
      "4           4     13792    0.068096\n",
      "5           5     11587    0.057209\n",
      "6           7     10370    0.051201\n",
      "7           9     10341    0.051057\n",
      "8           6     10131    0.050020\n",
      "9          10      9860    0.048682\n",
      "10          8      9697    0.047878\n",
      "11         11      8996    0.044417\n",
      "12         12      8578    0.042353\n",
      "13         14      7659    0.037815\n",
      "14         13      7152    0.035312\n"
     ]
    }
   ],
   "source": [
    "# Create df with document topic distribution (num docs per topic)\n",
    "topic_dist_df = doc_topic_df['dominant_topic'].value_counts().reset_index(name='Num docs')\n",
    "topic_dist_df.columns = ['Topic_num', 'Num_docs']\n",
    "topic_dist_df['Proportion'] = topic_dist_df.Num_docs.apply(lambda x: x / len(tweet_docs))\n",
    "print()\n",
    "print(topic_dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Word 0          Word 1   Word 2    Word 3    Word 4\n",
      "Topic0             trump            want     news      tell   politic\n",
      "Topic1              vote        american    trump     right  campaign\n",
      "Topic2   realdonaldtrump            call     give    debate     trump\n",
      "Topic3             trump         clinton  america  election     great\n",
      "Topic4             obama  hillaryclinton      gop      bill      isis\n",
      "Topic5             black       president    state     first     trump\n",
      "Topic6              love           trump      law      lead      late\n",
      "Topic7              take            time     stop      live     pjnet\n",
      "Topic8              know          medium     work     email      even\n",
      "Topic9             video         blicqer    thank       die      play\n",
      "Topic10              new           trump     show      year      maga\n",
      "Topic11          hillary             day    think       see   country\n",
      "Topic12             make            need    white  midnight   support\n",
      "Topic13            woman             man    never      life      back\n",
      "Topic14             good            tcot     look     today      kill\n"
     ]
    }
   ],
   "source": [
    "def top_keywords(feature_names, H):\n",
    "    keywords = np.array(feature_names)\n",
    "    topic_keywords = []\n",
    "    for weights in H:\n",
    "        topic_keywords_locs = (-weights).argsort()\n",
    "        topic_keywords.append(keywords.take(topic_keywords_locs))\n",
    "\n",
    "    return pd.DataFrame(topic_keywords)\n",
    "\n",
    "\n",
    "# Create df with top words (cols) per topic (rows)\n",
    "topic_words_df = top_keywords(tf_names, lda_H)\n",
    "topic_words_df.columns = word_names\n",
    "topic_words_df.index = topic_names\n",
    "print(topic_words_df.iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc_topic_df.to_csv('../scripts/topic_modeling_objects/topics_per_doc_LDA.csv', index=True)\n",
    "topic_dist_df.to_csv('../scripts/topic_modeling_objects/docs_per_topic_LDA.csv', index=False)\n",
    "topic_words_df.to_csv('../scripts/topic_modeling_objects/words_per_topic_LDA.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
