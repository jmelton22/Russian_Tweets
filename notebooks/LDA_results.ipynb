{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tweets = pd.read_csv('../tweets/tweets_clean.csv',\n",
    "                     header=0,\n",
    "                     parse_dates=['date'])\n",
    "tweets.dropna(subset=['lemmas'], inplace=True)\n",
    "tweets.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Load vectorizer\n",
    "with open('../scripts/topic_modeling_objects/sklearn_vect.joblib', 'rb') as f:\n",
    "    cv = joblib.load(f)\n",
    "\n",
    "# Load term frequency matrix\n",
    "with open('../scripts/topic_modeling_objects/sklearn_CV.joblib', 'rb') as f:\n",
    "    tf = joblib.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open('../scripts/topic_modeling_objects/sklearn_feature_names.joblib', 'rb') as f:\n",
    "    tf_names = joblib.load(f)\n",
    "\n",
    "# Load fitted LDA model\n",
    "with open('../scripts/topic_modeling_objects/sklearn_LDA_model.joblib', 'rb') as f:\n",
    "    lda_model = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: trump great lie first play donald always job word thing child anti check wait music\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 1: support try much use put become hear god city away sure anyone blacklivesmatter be record\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 2: realdonaldtrump campaign blicqer die keep big may free dnc liberal law nothing something merkelmussbleiben tax\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 3: make new love white live really lose house read speech care leave remember everyone fact\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 4: hillary see go people man never come gop back start ever black old happen racist\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 5: call video break hillaryclinton debate police must girl candidate russian name release point history watch\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 6: stop trump post attack potus tweet ask family stand twitter pay conservatexian national speak news\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 7: trump want politic medium win supporter republican gun rally lead conservative school high cnn issue\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 8: take news trump tell today still kill clinton money new war wikileak truth russia someone\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 9: say good day get trump show country poll voter election hillary dem guy trumpforpresident believe\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 10: year woman life thank way bad change mean feel late week fire next photo presidential\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 11: know america midnight world work even report fight end hate game people hope claim government\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 12: trump vote tcot president american maga time obama real state democrat last many people plan\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 13: think right need look muslim black watch help run friend refugee islamkill little foxnew shit\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 14: clinton obama give pjnet bill email talk find isis ccot party fbi terrorist neverhillary wakeupamerica\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tweets_orig = tweets.text.tolist()\n",
    "tweet_docs = tweets.lemmas.tolist()\n",
    "\n",
    "# Topic to document matrix (W) for LDA model\n",
    "lda_W = lda_model.transform(tf)\n",
    "# Word to topics matrix (H) for LDA model\n",
    "lda_H = lda_model.components_\n",
    "\n",
    "\n",
    "def display_topics(H, W, feature_names, orig_docs, n_words=15, n_docs=25):\n",
    "    for i, topic in enumerate(H):\n",
    "        print('Topic {}: '.format(i) + ' '.join([feature_names[word]\n",
    "                                                 for word in topic.argsort()[: (-n_words - 1): -1]]))\n",
    "        print()\n",
    "        top_doc_ids = np.argsort(W[:, i])[:: -1][0: n_docs]\n",
    "        for doc_id in top_doc_ids:\n",
    "            print('Tweet:', repr(orig_docs[doc_id]))\n",
    "        print('-' * 80)\n",
    "\n",
    "\n",
    "display_topics(lda_H, lda_W, tf_names, tweets_orig, n_docs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = ['Topic' + str(i) for i in range(len(lda_model.components_))]\n",
    "doc_names = ['Doc' + str(i) for i in range(len(tweet_docs))]\n",
    "word_names = ['Word ' + str(i) for i in range(len(tf_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  \\\n",
      "Doc0    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02   \n",
      "Doc1    0.07    0.07    0.07    0.07    0.07    0.07    0.07    0.07    0.07   \n",
      "Doc2    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
      "Doc3    0.03    0.53    0.03    0.03    0.03    0.03    0.03    0.03    0.03   \n",
      "Doc4    0.01    0.01    0.01    0.01    0.01    0.01    0.18    0.01    0.01   \n",
      "Doc5    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.17    0.01   \n",
      "Doc6    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.18    0.01   \n",
      "Doc7    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03   \n",
      "Doc8    0.01    0.01    0.01    0.18    0.01    0.01    0.01    0.68    0.01   \n",
      "Doc9    0.03    0.03    0.03    0.53    0.03    0.03    0.03    0.03    0.03   \n",
      "\n",
      "      Topic9  Topic10  Topic11  Topic12  Topic13  Topic14  dominant_topic  \n",
      "Doc0    0.02     0.02     0.69     0.02     0.02     0.02              11  \n",
      "Doc1    0.07     0.07     0.07     0.07     0.07     0.07               0  \n",
      "Doc2    0.01     0.81     0.01     0.01     0.01     0.01              10  \n",
      "Doc3    0.03     0.03     0.03     0.03     0.03     0.03               1  \n",
      "Doc4    0.01     0.01     0.01     0.68     0.01     0.01              12  \n",
      "Doc5    0.01     0.01     0.01     0.72     0.01     0.01              12  \n",
      "Doc6    0.71     0.01     0.01     0.01     0.01     0.01               9  \n",
      "Doc7    0.03     0.53     0.03     0.03     0.03     0.03              10  \n",
      "Doc8    0.01     0.01     0.01     0.01     0.01     0.01               7  \n",
      "Doc9    0.03     0.03     0.03     0.03     0.03     0.03               3  \n"
     ]
    }
   ],
   "source": [
    "# Create df with the topic probabilities (cols) for each doc (rows)\n",
    "doc_topic_df = pd.DataFrame(np.round(lda_W, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# Add column with dominant topic for each doc\n",
    "doc_topic_df['dominant_topic'] = np.argmax(doc_topic_df.values, axis=1)\n",
    "print(doc_topic_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Topic_num  Num_docs  Proportion\n",
      "0           0     29039    0.143359\n",
      "1           2     24763    0.122250\n",
      "2           1     17709    0.087426\n",
      "3           3     15079    0.074442\n",
      "4           4     14414    0.071159\n",
      "5           7     13285    0.065585\n",
      "6           8     11923    0.058861\n",
      "7          12     11727    0.057894\n",
      "8           9     11439    0.056472\n",
      "9           5     10331    0.051002\n",
      "10          6      9857    0.048662\n",
      "11         14      9310    0.045961\n",
      "12         11      8464    0.041785\n",
      "13         10      8217    0.040566\n",
      "14         13      7004    0.034577\n"
     ]
    }
   ],
   "source": [
    "# Create df with document topic distribution (num docs per topic)\n",
    "topic_dist_df = doc_topic_df['dominant_topic'].value_counts().reset_index(name='Num docs')\n",
    "topic_dist_df.columns = ['Topic_num', 'Num_docs']\n",
    "topic_dist_df['Proportion'] = topic_dist_df.Num_docs.apply(lambda x: x / len(tweet_docs))\n",
    "print()\n",
    "print(topic_dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Word 0    Word 1    Word 2          Word 3    Word 4\n",
      "Topic0             trump     great       lie           first      play\n",
      "Topic1           support       try      much             use       put\n",
      "Topic2   realdonaldtrump  campaign   blicqer             die      keep\n",
      "Topic3              make       new      love           white      live\n",
      "Topic4           hillary       see        go          people       man\n",
      "Topic5              call     video     break  hillaryclinton    debate\n",
      "Topic6              stop     trump      post          attack     potus\n",
      "Topic7             trump      want   politic          medium       win\n",
      "Topic8              take      news     trump            tell     today\n",
      "Topic9               say      good       day             get     trump\n",
      "Topic10             year     woman      life           thank       way\n",
      "Topic11             know   america  midnight           world      work\n",
      "Topic12            trump      vote      tcot       president  american\n",
      "Topic13            think     right      need            look    muslim\n",
      "Topic14          clinton     obama      give           pjnet      bill\n"
     ]
    }
   ],
   "source": [
    "def top_keywords(feature_names, H):\n",
    "    keywords = np.array(feature_names)\n",
    "    topic_keywords = []\n",
    "    for weights in H:\n",
    "        topic_keywords_locs = (-weights).argsort()\n",
    "        topic_keywords.append(keywords.take(topic_keywords_locs))\n",
    "\n",
    "    return pd.DataFrame(topic_keywords)\n",
    "\n",
    "\n",
    "# Create df with top words (cols) per topic (rows)\n",
    "topic_words_df = top_keywords(tf_names, lda_H)\n",
    "topic_words_df.columns = word_names\n",
    "topic_words_df.index = topic_names\n",
    "print(topic_words_df.iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc_topic_df.to_csv('../scripts/topic_modeling_objects/topics_per_doc_LDA.csv', index=True)\n",
    "topic_dist_df.to_csv('../scripts/topic_modeling_objects/docs_per_topic_LDA.csv', index=False)\n",
    "topic_words_df.to_csv('../scripts/topic_modeling_objects/words_per_topic_LDA.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
