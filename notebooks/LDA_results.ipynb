{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tweets = pd.read_csv('../tweets/tweets_clean.csv',\n",
    "                     header=0,\n",
    "                     parse_dates=['date'])\n",
    "tweets.dropna(subset=['lemmas'], inplace=True)\n",
    "\n",
    "# Load vectorizer\n",
    "with open('../scripts/topic_modeling_objects/sklearn_vect.joblib', 'rb') as f:\n",
    "    cv = joblib.load(f)\n",
    "\n",
    "# Load term frequency matrix\n",
    "with open('../scripts/topic_modeling_objects/sklearn_CV.joblib', 'rb') as f:\n",
    "    tf = joblib.load(f)\n",
    "\n",
    "# Load feature names\n",
    "with open('../scripts/topic_modeling_objects/sklearn_feature_names.joblib', 'rb') as f:\n",
    "    tf_names = joblib.load(f)\n",
    "\n",
    "# Load fitted LDA model\n",
    "with open('../scripts/topic_modeling_objects/sklearn_LDA_model.joblib', 'rb') as f:\n",
    "    lda_model = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: trump clinton year show life bill attack potus change donald ask job plan rally dem\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 1: news tell people break police really play refugee everyone hear meet school wait name high\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 2: think would call woman right need thank let pjnet way help bad ccot realdonaldtrump mean\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 3: make trump politic tcot love state big may money usa face sign conservative bring government\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 4: good black see trump video watch world first debate could start say must happen people\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 5: go man never medium back pay ever trump tweet old many twitter girl believe tax\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 6: know president clinton leave find run email war wikileak russia game illegal also release send\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 7: want trump stop great time voter always poll national cnn order fake miss little trumppence16\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 8: get say day trump country win obama report last gun truth want something people deal\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 9: white realdonaldtrump blicqer die keep house free liberal law nothing muslim guy merkelmussbleiben night merkel\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 10: vote american maga trump midnight lie stand child hillary lead happy true leader power christma\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 11: obama america gop hillaryclinton give support today still kill isis dnc terrorist trumpforpresident someone fight\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 12: new trump campaign post real supporter friend conservatexian check follow fact kid candidate music health\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 13: election come live try talk lose party read speech feel join turn next long everything\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Topic 14: take hillary look use thing work even democrat fbi do people hate week hope claim\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tweets_orig = tweets.text.tolist()\n",
    "tweet_docs = tweets.lemmas.tolist()\n",
    "\n",
    "# Topic to document matrix (W) for LDA model\n",
    "lda_W = lda_model.transform(tf)\n",
    "# Word to topics matrix (H) for LDA model\n",
    "lda_H = lda_model.components_\n",
    "\n",
    "\n",
    "def display_topics(H, W, feature_names, orig_docs, n_words=15, n_docs=25):\n",
    "    for i, topic in enumerate(H):\n",
    "        print('Topic {}: '.format(i) + ' '.join([feature_names[word]\n",
    "                                                 for word in topic.argsort()[: (-n_words - 1): -1]]))\n",
    "        print()\n",
    "        top_doc_ids = np.argsort(W[:, i])[:: -1][0: n_docs]\n",
    "        for doc_id in top_doc_ids:\n",
    "            print('Tweet:', repr(orig_docs[doc_id]))\n",
    "        print('-' * 80)\n",
    "\n",
    "\n",
    "display_topics(lda_H, lda_W, tf_names, tweets_orig, n_docs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = ['Topic' + str(i) for i in range(len(lda_model.components_))]\n",
    "doc_names = ['Doc' + str(i) for i in range(len(tweet_docs))]\n",
    "word_names = ['Word ' + str(i) for i in range(len(tf_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  \\\n",
      "Doc0    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02   \n",
      "Doc1    0.07    0.07    0.07    0.07    0.07    0.07    0.07    0.07    0.07   \n",
      "Doc2    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
      "Doc3    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03    0.03   \n",
      "Doc4    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.68    0.01   \n",
      "Doc5    0.17    0.01    0.01    0.60    0.01    0.01    0.01    0.01    0.01   \n",
      "Doc6    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.61    0.16   \n",
      "Doc7    0.03    0.03    0.53    0.03    0.03    0.03    0.03    0.03    0.03   \n",
      "Doc8    0.68    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
      "Doc9    0.03    0.03    0.03    0.03    0.53    0.03    0.03    0.03    0.03   \n",
      "\n",
      "      Topic9  Topic10  Topic11  Topic12  Topic13  Topic14  dominant_topic  \n",
      "Doc0    0.69     0.02     0.02     0.02     0.02     0.02               9  \n",
      "Doc1    0.07     0.07     0.07     0.07     0.07     0.07               0  \n",
      "Doc2    0.01     0.01     0.01     0.01     0.81     0.01              13  \n",
      "Doc3    0.03     0.03     0.03     0.53     0.03     0.03              12  \n",
      "Doc4    0.01     0.01     0.01     0.18     0.01     0.01               7  \n",
      "Doc5    0.01     0.01     0.01     0.01     0.13     0.01               3  \n",
      "Doc6    0.01     0.01     0.13     0.01     0.01     0.01               7  \n",
      "Doc7    0.03     0.03     0.03     0.03     0.03     0.03               2  \n",
      "Doc8    0.01     0.01     0.01     0.01     0.18     0.01               0  \n",
      "Doc9    0.03     0.03     0.03     0.03     0.03     0.03               4  \n"
     ]
    }
   ],
   "source": [
    "# Create df with the topic probabilities (cols) for each doc (rows)\n",
    "doc_topic_df = pd.DataFrame(np.round(lda_W, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# Add column with dominant topic for each doc\n",
    "doc_topic_df['dominant_topic'] = np.argmax(doc_topic_df.values, axis=1)\n",
    "print(doc_topic_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Topic_num  Num_docs  Proportion\n",
      "0           0     33299    0.164379\n",
      "1           2     21810    0.107664\n",
      "2           1     18944    0.093516\n",
      "3           3     17015    0.083994\n",
      "4           4     16211    0.080025\n",
      "5           8     12821    0.063290\n",
      "6           9     12168    0.060067\n",
      "7           6     11281    0.055688\n",
      "8           5     10857    0.053595\n",
      "9           7      9963    0.049182\n",
      "10         10      9570    0.047242\n",
      "11         11      9312    0.045968\n",
      "12         12      7546    0.037251\n",
      "13         14      6396    0.031574\n",
      "14         13      5381    0.026563\n"
     ]
    }
   ],
   "source": [
    "# Create df with document topic distribution (num docs per topic)\n",
    "topic_dist_df = doc_topic_df['dominant_topic'].value_counts().reset_index(name='Num docs')\n",
    "topic_dist_df.columns = ['Topic_num', 'Num_docs']\n",
    "topic_dist_df['Proportion'] = topic_dist_df.Num_docs.apply(lambda x: x / len(tweet_docs))\n",
    "print()\n",
    "print(topic_dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word 0           Word 1    Word 2          Word 3    Word 4\n",
      "Topic0      trump          clinton      year            show      life\n",
      "Topic1       news             tell    people           break    police\n",
      "Topic2      think            would      call           woman     right\n",
      "Topic3       make            trump   politic            tcot      love\n",
      "Topic4       good            black       see           trump     video\n",
      "Topic5         go              man     never          medium      back\n",
      "Topic6       know        president   clinton           leave      find\n",
      "Topic7       want            trump      stop           great      time\n",
      "Topic8        get              say       day           trump   country\n",
      "Topic9      white  realdonaldtrump   blicqer             die      keep\n",
      "Topic10      vote         american      maga           trump  midnight\n",
      "Topic11     obama          america       gop  hillaryclinton      give\n",
      "Topic12       new            trump  campaign            post      real\n",
      "Topic13  election             come      live             try      talk\n",
      "Topic14      take          hillary      look             use     thing\n"
     ]
    }
   ],
   "source": [
    "def top_keywords(feature_names, H):\n",
    "    keywords = np.array(feature_names)\n",
    "    topic_keywords = []\n",
    "    for weights in H:\n",
    "        topic_keywords_locs = (-weights).argsort()\n",
    "        topic_keywords.append(keywords.take(topic_keywords_locs))\n",
    "\n",
    "    return pd.DataFrame(topic_keywords)\n",
    "\n",
    "\n",
    "# Create df with top words (cols) per topic (rows)\n",
    "topic_words_df = top_keywords(tf_names, lda_H)\n",
    "topic_words_df.columns = word_names\n",
    "topic_words_df.index = topic_names\n",
    "print(topic_words_df.iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc_topic_df.to_csv('../scripts/topic_modeling_objects/topics_per_doc_LDA.csv', index=True)\n",
    "topic_dist_df.to_csv('../scripts/topic_modeling_objects/docs_per_topic_LDA.csv', index=False)\n",
    "topic_words_df.to_csv('../scripts/topic_modeling_objects/words_per_topic_LDA.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
